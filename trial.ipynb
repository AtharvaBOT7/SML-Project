{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8be5652",
   "metadata": {},
   "source": [
    "### Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da20787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.4.1\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f194e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['FAKE', 'REAL'] (class_to_idx: {'FAKE': 0, 'REAL': 1} )\n",
      "FULL train:100000  FULL test:20000\n",
      "SUBSET train:8000  val:2000  test:2000\n"
     ]
    }
   ],
   "source": [
    "# STEP 2 — CIFAKE loader for structure: data/{train,test}/{FAKE,REAL}\n",
    "import os, math, torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# --- config (matches your screenshot) ---\n",
    "ROOT_DIR   = \"data\"          # contains 'train' and 'test'\n",
    "IMG_SIZE   = 224\n",
    "BATCH      = 64\n",
    "FRACTION   = 0.10            # use only 10% per split for a quick run\n",
    "VAL_RATIO  = 0.20            # build a stratified val from TRAIN\n",
    "SEED       = 42\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "tf_eval = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "def stratified_split_indices(samples, num_classes, val_ratio, fraction, generator):\n",
    "    per_class = {c: [] for c in range(num_classes)}\n",
    "    for idx, (_, cls) in enumerate(samples):\n",
    "        per_class[cls].append(idx)\n",
    "\n",
    "    train_keep, val_keep = [], []\n",
    "    for c, idxs in per_class.items():\n",
    "        if not idxs: continue\n",
    "        perm = torch.randperm(len(idxs), generator=generator).tolist()\n",
    "        idxs = [idxs[i] for i in perm]\n",
    "        k_frac = max(1, math.floor(len(idxs) * fraction))  # take only a fraction\n",
    "        idxs = idxs[:k_frac]\n",
    "        k_val = max(1, math.floor(len(idxs) * val_ratio))  # carve out val\n",
    "        val_keep.extend(idxs[:k_val])\n",
    "        train_keep.extend(idxs[k_val:])\n",
    "\n",
    "    tperm = torch.randperm(len(train_keep), generator=generator).tolist()\n",
    "    vperm = torch.randperm(len(val_keep),   generator=generator).tolist()\n",
    "    train_keep = [train_keep[i] for i in tperm]\n",
    "    val_keep   = [val_keep[i]   for i in vperm]\n",
    "    return train_keep, val_keep\n",
    "\n",
    "def stratified_subset_indices(samples, num_classes, fraction, generator):\n",
    "    per_class = {c: [] for c in range(num_classes)}\n",
    "    for idx, (_, cls) in enumerate(samples):\n",
    "        per_class[cls].append(idx)\n",
    "    keep = []\n",
    "    for c, idxs in per_class.items():\n",
    "        perm = torch.randperm(len(idxs), generator=generator).tolist()\n",
    "        k = max(1, math.floor(len(idxs) * fraction))\n",
    "        keep.extend([idxs[i] for i in perm[:k]])\n",
    "    perm_all = torch.randperm(len(keep), generator=generator).tolist()\n",
    "    return [keep[i] for i in perm_all]\n",
    "\n",
    "# build datasets from your structure\n",
    "train_full = datasets.ImageFolder(os.path.join(ROOT_DIR, \"train\"), transform=tf_train)\n",
    "test_full  = datasets.ImageFolder(os.path.join(ROOT_DIR, \"test\"),  transform=tf_eval)\n",
    "\n",
    "train_idx, val_idx = stratified_split_indices(\n",
    "    train_full.samples, num_classes=len(train_full.classes),\n",
    "    val_ratio=VAL_RATIO, fraction=FRACTION, generator=g\n",
    ")\n",
    "test_idx = stratified_subset_indices(test_full.samples, len(test_full.classes), FRACTION, g)\n",
    "\n",
    "# wrap as subsets (val uses eval transforms)\n",
    "val_full = datasets.ImageFolder(os.path.join(ROOT_DIR, \"train\"), transform=tf_eval)\n",
    "train_ds = Subset(train_full, train_idx)\n",
    "val_ds   = Subset(val_full,   val_idx)\n",
    "test_ds  = Subset(test_full,  test_idx)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"classes:\", train_full.classes, \"(class_to_idx:\", train_full.class_to_idx, \")\")\n",
    "print(f\"FULL train:{len(train_full)}  FULL test:{len(test_full)}\")\n",
    "print(f\"SUBSET train:{len(train_ds)}  val:{len(val_ds)}  test:{len(test_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ea6c79",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "User specified an unsupported autocast device_type 'mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m xb,yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     27\u001b[0m     loss \u001b[38;5;241m=\u001b[39m crit(model(xb), yb)\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/amp/autocast_mode.py:238\u001b[0m, in \u001b[0;36mautocast.__init__\u001b[0;34m(self, device_type, dtype, enabled, cache_enabled)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device_type\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_autocast_available(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser specified an unsupported autocast device_type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfast_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_autocast_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: User specified an unsupported autocast device_type 'mps'"
     ]
    }
   ],
   "source": [
    "# STEP 3 — Minimal ResNet-18 train + validate on CIFAKE subset\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# build model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)   # binary classification\n",
    "model.to(device)\n",
    "\n",
    "# loss + optimizer\n",
    "crit = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "opt  = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=5e-4)\n",
    "\n",
    "EPOCHS = 3  # short test run\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # training\n",
    "    model.train()\n",
    "    for xb,yb in train_dl:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        with torch.autocast(device_type=\"mps\", dtype=torch.float16, enabled=torch.backends.mps.is_available()):\n",
    "            loss = crit(model(xb), yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(f\"epoch {epoch}: train loss {loss.item():.4f}\")\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    all_y, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in val_dl:\n",
    "            xb = xb.to(device)\n",
    "            with torch.autocast(device_type=\"mps\", dtype=torch.float16, enabled=torch.backends.mps.is_available()):\n",
    "                logits = model(xb)\n",
    "            preds = logits.argmax(1).cpu()\n",
    "            all_pred.extend(preds.numpy())\n",
    "            all_y.extend(yb.numpy())\n",
    "    acc = accuracy_score(all_y, all_pred)\n",
    "    f1  = f1_score(all_y, all_pred)\n",
    "    print(f\"   val acc {acc:.3f}, f1 {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df78761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.4.1\n",
      "torchvision: 0.19.1\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c753e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import nullcontext\n",
    "import torch\n",
    "\n",
    "def mps_autocast():\n",
    "    # Only use autocast if (1) MPS is built, (2) MPS is available at runtime, and\n",
    "    # (3) autocast(\"mps\") actually works in this wheel.\n",
    "    try:\n",
    "        if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_built() and torch.backends.mps.is_available():\n",
    "            # Probe once: if constructing the context fails, we fall back.\n",
    "            _ = torch.autocast(device_type=\"mps\", dtype=torch.float16)\n",
    "            return torch.autocast(device_type=\"mps\", dtype=torch.float16)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return nullcontext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "942ffc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.4.1\n",
      "torchvision: 0.19.1\n",
      "Using device: cpu\n",
      "classes: ['FAKE', 'REAL'] (class_to_idx: {'FAKE': 0, 'REAL': 1} )\n",
      "FULL train:100000  FULL test:20000\n",
      "SUBSET train:8000  val:2000  test:2000\n",
      "Epoch 01 | train loss 0.3811 | val Acc 0.896 F1 0.886 AUROC 0.036\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 137\u001b[0m\n\u001b[1;32m    135\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    136\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 137\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# FP32 CPU\u001b[39;00m\n\u001b[1;32m    138\u001b[0m loss   \u001b[38;5;241m=\u001b[39m criterion(logits, yb)\n\u001b[1;32m    139\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torchvision/models/resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torchvision/models/resnet.py:92\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     90\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 92\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Fall 2025/SML/SML-Project/smlproject/lib/python3.10/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CIFAKE -> ResNet-18 (CPU)\n",
    "# =========================\n",
    "\n",
    "# -------- CONFIG --------\n",
    "ROOT_DIR   = \"data\"   # contains 'train' and 'test' with subfolders FAKE/REAL\n",
    "IMG_SIZE   = 224\n",
    "BATCH      = 64\n",
    "FRACTION   = 0.10     # use only 10% of each split to move fast; set to 1.0 for all data\n",
    "VAL_RATIO  = 0.20     # from TRAIN (after fraction), carve out 20% for validation\n",
    "EPOCHS     = 3\n",
    "LR         = 3e-4\n",
    "WEIGHT_DECAY = 5e-4\n",
    "LABEL_SMOOTH = 0.1\n",
    "SEED       = 42\n",
    "NUM_WORKERS = 2\n",
    "# ------------------------\n",
    "\n",
    "import os, math, random, numpy as np\n",
    "import torch, torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn, torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Force CPU (avoids any MPS/autocast issues)\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --------- Transforms ----------\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "tf_eval = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# --------- Helpers ----------\n",
    "def stratified_split_indices(samples, num_classes, val_ratio, fraction, seed=SEED):\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    per_class = {c: [] for c in range(num_classes)}\n",
    "    for idx, (_, cls) in enumerate(samples):\n",
    "        per_class[cls].append(idx)\n",
    "\n",
    "    train_keep, val_keep = [], []\n",
    "    for c, idxs in per_class.items():\n",
    "        if not idxs: \n",
    "            continue\n",
    "        perm = torch.randperm(len(idxs), generator=g).tolist()\n",
    "        idxs = [idxs[i] for i in perm]\n",
    "        k_frac = max(1, math.floor(len(idxs) * fraction))  # fraction first\n",
    "        idxs = idxs[:k_frac]\n",
    "        k_val = max(1, math.floor(len(idxs) * val_ratio))  # carve val\n",
    "        val_keep.extend(idxs[:k_val])\n",
    "        train_keep.extend(idxs[k_val:])\n",
    "    # shuffle\n",
    "    if train_keep:\n",
    "        perm = torch.randperm(len(train_keep), generator=g).tolist()\n",
    "        train_keep = [train_keep[i] for i in perm]\n",
    "    if val_keep:\n",
    "        perm = torch.randperm(len(val_keep), generator=g).tolist()\n",
    "        val_keep = [val_keep[i] for i in perm]\n",
    "    return train_keep, val_keep\n",
    "\n",
    "def stratified_subset_indices(samples, num_classes, fraction, seed=SEED):\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    per_class = {c: [] for c in range(num_classes)}\n",
    "    for idx, (_, cls) in enumerate(samples):\n",
    "        per_class[cls].append(idx)\n",
    "    keep = []\n",
    "    for c, idxs in per_class.items():\n",
    "        if not idxs: continue\n",
    "        perm = torch.randperm(len(idxs), generator=g).tolist()\n",
    "        k = max(1, math.floor(len(idxs) * fraction))\n",
    "        keep.extend([idxs[i] for i in perm[:k]])\n",
    "    if keep:\n",
    "        perm = torch.randperm(len(keep), generator=g).tolist()\n",
    "        keep = [keep[i] for i in perm]\n",
    "    return keep\n",
    "\n",
    "# --------- Datasets / Loaders ----------\n",
    "train_full = datasets.ImageFolder(os.path.join(ROOT_DIR, \"train\"), transform=tf_train)\n",
    "test_full  = datasets.ImageFolder(os.path.join(ROOT_DIR, \"test\"),  transform=tf_eval)\n",
    "\n",
    "train_idx, val_idx = stratified_split_indices(\n",
    "    train_full.samples, num_classes=len(train_full.classes),\n",
    "    val_ratio=VAL_RATIO, fraction=FRACTION, seed=SEED\n",
    ")\n",
    "test_idx = stratified_subset_indices(test_full.samples, len(test_full.classes), FRACTION, seed=SEED)\n",
    "\n",
    "val_full = datasets.ImageFolder(os.path.join(ROOT_DIR, \"train\"), transform=tf_eval)\n",
    "train_ds = Subset(train_full, train_idx)\n",
    "val_ds   = Subset(val_full,   val_idx)\n",
    "test_ds  = Subset(test_full,  test_idx)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=False)\n",
    "val_dl   = DataLoader(val_ds,  batch_size=BATCH, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)\n",
    "test_dl  = DataLoader(test_ds, batch_size=BATCH, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)\n",
    "\n",
    "print(\"classes:\", train_full.classes, \"(class_to_idx:\", train_full.class_to_idx, \")\")\n",
    "print(f\"FULL train:{len(train_full)}  FULL test:{len(test_full)}\")\n",
    "print(f\"SUBSET train:{len(train_ds)}  val:{len(val_ds)}  test:{len(test_ds)}\")\n",
    "\n",
    "# Identify which class index to treat as \"positive\" for AUROC\n",
    "# Here we'll use 'FAKE' as positive if it exists, else class 1.\n",
    "cls_to_idx = train_full.class_to_idx\n",
    "pos_idx = cls_to_idx.get(\"FAKE\", 1)\n",
    "\n",
    "# --------- Model / Optim ---------\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# --------- Train + Val ----------\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)          # FP32 CPU\n",
    "        loss   = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "    train_loss = running_loss / len(train_dl.dataset)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    y_prob_pos = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs  = torch.softmax(logits, dim=1)\n",
    "            preds  = logits.argmax(1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(yb.numpy())\n",
    "            y_prob_pos.extend(probs[:, pos_idx].cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred)\n",
    "    try:\n",
    "        auroc = roc_auc_score(y_true, np.array(y_prob_pos))\n",
    "    except Exception:\n",
    "        auroc = float(\"nan\")\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train loss {train_loss:.4f} | val Acc {acc:.3f} F1 {f1:.3f} AUROC {auroc:.3f}\")\n",
    "\n",
    "# --------- Test Evaluation ----------\n",
    "model.eval()\n",
    "y_true, y_pred, y_prob_pos = [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dl:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        probs  = torch.softmax(logits, dim=1)\n",
    "        preds  = logits.argmax(1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(yb.numpy())\n",
    "        y_prob_pos.extend(probs[:, pos_idx].cpu().numpy())\n",
    "\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "test_f1  = f1_score(y_true, y_pred)\n",
    "try:\n",
    "    test_auroc = roc_auc_score(y_true, np.array(y_prob_pos))\n",
    "except Exception:\n",
    "    test_auroc = float(\"nan\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\n=== TEST RESULTS ===\")\n",
    "print(f\"Accuracy: {test_acc:.4f}  F1: {test_f1:.4f}  AUROC: {test_auroc:.4f}\")\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ccfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3363b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a98cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deec396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfddef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9c748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ec12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4daa8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b499a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4077a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
